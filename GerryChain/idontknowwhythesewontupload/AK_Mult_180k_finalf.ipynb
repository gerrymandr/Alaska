{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at matchings of stationary House plan\n",
    "*and* \n",
    "Chain on graph with 30k matchings (aka strict adjacency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gerrychain import Graph, Partition, Election\n",
    "from gerrychain.updaters import Tally, cut_edges\n",
    "import json\n",
    "import networkx\n",
    "from gerrychain import MarkovChain\n",
    "from gerrychain.constraints import single_flip_contiguous, no_more_discontiguous\n",
    "from gerrychain.proposals import propose_random_flip\n",
    "from gerrychain.accept import always_accept\n",
    "import pandas\n",
    "from gerrychain import (GeographicPartition, Partition, Graph, MarkovChain,\n",
    "                        proposals, updaters, constraints, accept, Election)\n",
    "from functools import partial\n",
    "from gerrychain.proposals import recom\n",
    " \n",
    "from gerrychain.constraints.validity import within_percent_of_ideal_population\n",
    "import matplotlib.pyplot as plt\n",
    "import gerrychain \n",
    "import numpy\n",
    "import geopandas as gpd\n",
    "#NOTE: must have tqdm installed (pip install tqdm in terminal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build Graph, either from .shp or .json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#graph = Graph.from_file(\"/Users/caranix/Desktop/Alaska_Git/AK_precincts_ns/AK_precincts_ns.shp\")\n",
    "#Graph.to_json(graph, \"/Users/caranix/Documents/MGGG/AK_graph_ns.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/caranix/Desktop/GerryChain/gerrychain/graph/graph.py:216: UserWarning: Found islands (degree-0 nodes). Indices of islands: {352, 394, 372, 351}\n",
      "  \"Found islands (degree-0 nodes). Indices of islands: {}\".format(islands)\n"
     ]
    }
   ],
   "source": [
    "G_loose = Graph.from_json(\"/Users/caranix/Documents/MGGG/AK_graph_ns.json\")\n",
    "#G_restricted = Graph.from_json(\"/Users/caranix/Documents/MGGG/AK_graph_ns.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= gpd.read_file(\"/Users/caranix/Desktop/Alaska_Git/AK_precincts_ns/AK_precincts_ns.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph= networkx.Graph(G_loose)\n",
    "\n",
    "idict={}\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "\n",
    "\tidict[int(row[\"ID\"])] = index\n",
    "\t\n",
    "\t\n",
    "to_add2 = [(426,444), (437,438), (437,436), (437,423), (437,428), (437,432), (437,374), (437,441), \n",
    "(437,443), (437,439), (437,427), (437,430), (437,445), (437,435), (437,434), (437,442), (411,420),\n",
    "(411,414), (411,358),(411,407), (399,400),(399,349),(381,384),(240,210), (400,411), (399,348),\n",
    "(399,381),(399,384),(399,386),(399,397)]\n",
    "\n",
    "for i in range(len(to_add2)):\n",
    "\tG_loose.add_edge(idict[to_add2[i][0]],idict[to_add2[i][1]])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1151\n"
     ]
    }
   ],
   "source": [
    "print(len(G_loose.edges()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(G_restricted.edges()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#G_restricted= networkx.Graph(G_restricted)\n",
    "#G_restricted.number_of_edges() #in restricted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#G_loose= networkx.Graph(G_loose)\n",
    "#G_loose.number_of_edges() #in restricted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make dataframe from shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Manually\" add/remove edges from graph that are problematic (aka add island edges and remove excess edges)\n",
    "Note: Use to_add for 30k runs and to_add2 for 180k runs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idict={}\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "\n",
    "\tidict[int(row[\"ID\"])] = index\n",
    "\t\n",
    "\t\n",
    "to_add = [(426,444), (437,438),(437,442),(411,420),\n",
    "(411,414), (411,358),(411,407),(399,400),(399,349),(381,384),(240,210)]\n",
    "\t\n",
    "to_add2 = [(426,444), (437,438), (437,436), (437,423), (437,428), (437,432), (437,374), (437,441), \n",
    "(437,443), (437,439), (437,427), (437,430), (437,445), (437,435), (437,434), (437,442), (411,420),\n",
    "(411,414), (411,358),(411,407), (399,400),(399,349),(381,384),(240,210), (400,411), (399,348),\n",
    "(399,381),(399,384),(399,386),(399,397)]\n",
    "\n",
    "\n",
    "for i in range(len(to_add)):\n",
    "\tgraph.add_edge(idict[to_add[i][0]],idict[to_add[i][1]])\n",
    "\t\n",
    "\t\n",
    "\t\n",
    "\t\n",
    "\t\n",
    "\n",
    "to_remove = [(210,195),(210,203),(210,202),(210,193),(210,235),(210,234),(169,78),(169,77),(169,70),\n",
    "(169,68),(169,32),(169,23),(169,179),(234,78),(235,78),(235,89),(235,106),(235,102),(102,190),\n",
    "(190,105),(190,145),(145,233),(233,133)]\n",
    "\n",
    "for i in range(len(to_remove)):\n",
    "    graph.remove_edge(idict[to_remove[i][0]],idict[to_remove[i][1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#G= networkx.Graph(G_restricted)\n",
    "#G.number_of_edges() #in loose "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function for pulling out adj matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parts_adjacency_matrix(partition):\n",
    "    parts_graph = networkx.Graph()\n",
    "    for part in partition.parts:\n",
    "        parts_graph.add_node(part)\n",
    "    for edge in partition['cut_edges']:\n",
    "        source, destination = (partition.assignment[node] for node in edge)\n",
    "        parts_graph.add_edge(source, destination)\n",
    "    nodelist = sorted(list(partition.parts.keys()))\n",
    "    return networkx.to_numpy_matrix(parts_graph, nodelist=nodelist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add non-native american population "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"nAMIN\"] = df[\"TOTPOP\"]-df[\"AMIN\"]\n",
    "G_loose.join(df,columns= [\"nAMIN\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[\"nAMIN\"] = df[\"TOTPOP\"]-df[\"AMIN\"]\n",
    "#G_restricted.join(df,columns= [\"nAMIN\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#outmat = parts_adjacency_matrix(ip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#election = gerrychain.Election(\"AK\", [\"PRES16\", \"USH14\", \"SEN16\",\"GOV18\",\"USH16\",\"USH18\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build elections object and add updaters + make intial parition (inital partition for stationary graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "elections = [\n",
    "    Election(\"GOV18x\", {\"Democratic\": \"GOV18D_x\", \"Republican\": \"GOV18R_x\"}),\n",
    "    Election(\"USH18x\", {\"Democratic\": \"USH18D_x\", \"Republican\": \"USH18R_x\"}),\n",
    "    Election(\"GOV18ns\", {\"Democratic\": \"GOV18D_NS\", \"Republican\": \"GOV18R_NS\"}),\n",
    "    Election(\"USH18ns\", {\"Democratic\": \"USH18D_NS\", \"Republican\": \"USH18R_NS\"}),\n",
    "    Election(\"Native_percent\", {\"Native\":\"AMIN\", \"nonNative\":\"nAMIN\"})\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#graph= G_loose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#updaters = {\"population\": gerrychain.updaters.Tally(\"POPULATION\", alias=\"population\"), \"AK\": election, \"cut_edges\": gerrychain.updaters.cut_edges}\n",
    "my_updaters = {\"population\": updaters.Tally(\"POPULATION\", alias=\"population\")}\n",
    "\n",
    "election_updaters = {election.name: election for election in elections}\n",
    "my_updaters.update(election_updaters)\n",
    "\n",
    "# Create an initial partition\n",
    "initial_partition = GeographicPartition(G_loose, assignment=\"HDIST\", updaters=my_updaters) #NOTE: assignment based on House Districts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(\"/Users/caranix/Desktop/Alaska_Git/data/small_matchings.json\", 'r') as rf:\n",
    " #   matchings= json.load(rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FOR STATIONARY GRAPH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parts = []\n",
    "percents1 = []\n",
    "wins1 = []\n",
    "percents2 = []\n",
    "wins2 = []\n",
    "percents3 = []\n",
    "wins3 = []\n",
    "percents4 = []\n",
    "wins4 = []\n",
    "\n",
    "for i in range(len(matchings)):\n",
    "    temp= {x: 0 for x in range(40)}\n",
    "    for j in range(20):\n",
    "        for k in [0,1]:\n",
    "            temp[matchings[str(i)][j][k]]=j\n",
    "    df[\"SENDIST\"] = df[\"HDIST\"].map(temp)\n",
    "    c_part = GeographicPartition(graph, assignment=df[\"SENDIST\"], updaters= my_updaters)\n",
    "    wins1.append(c_part[\"GOV18x\"].wins(\"Democratic\"))\n",
    "    percents1.append(sorted(c_part[\"GOV18x\"].percents(\"Democratic\")))\n",
    "    wins2.append(c_part[\"GOV18ns\"].wins(\"Democratic\"))\n",
    "    percents2.append(sorted(c_part[\"GOV18ns\"].percents(\"Democratic\")))\n",
    "    wins3.append(c_part[\"USH18x\"].wins(\"Democratic\"))\n",
    "    percents3.append(sorted(c_part[\"USH18x\"].percents(\"Democratic\")))\n",
    "    wins4.append(c_part[\"USH18ns\"].wins(\"Democratic\"))\n",
    "    percents4.append(sorted(c_part[\"USH18ns\"].percents(\"Democratic\")))\n",
    "#print(wins)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ip = GeographicPartition(graph, assignment=df[\"HDIST\"], updaters= my_updaters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#{(initial_partition.assignment[x[0]],initial_partition.assignment[x[1]]) for x in initial_partition[\"cut_edges\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some visualization stuff "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "new_dg = nx.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dg = nx.Graph()\n",
    "new_dg.add_edges_from(list({(ip.assignment[x[0]],ip.assignment[x[1]]) for x in ip[\"cut_edges\"]}) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(new_dg)\n",
    "with open('AK_inital_state_fixedagain.json', \"w\") as m:\n",
    "    m.write(json.dumps(nx.adjacency_matrix(new_dg).todense().tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ip[\"GOV18x\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initial_partition = GeographicPartition(graph, assignment=\"HDIST\", updaters=my_updaters) #NOTE: assignment based on House Districts\n",
    "#sorted(initial_partition[\"Native_percent\"].percents(\"Native\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ip = GeographicPartition(graph, assignment=df[\"SENDIST\"], updaters= my_updaters)\n",
    "\n",
    "#ip[\"GOV18ns\"].wins(\"Democratic\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "sns.distplot(wins1,kde=False)\n",
    "#plt.axvline(x=ip[\"SENDIST\"].wins(\"Democratic\"),color='r',label='Enacted')\n",
    "plt.axvline(x=6, color='b', label='Democratic Caucus')\n",
    "plt.axvline(x=7, color='purple', label='Democratic Senators')\n",
    "plt.axvline(x=np.mean(wins1),color='g',label='Matchings Mean')\n",
    "plt.savefig('GOV18x_matchings.png')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(percents4[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idict[426] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wins2.count(10))\n",
    "print(wins2.count(9))\n",
    "print(wins2.count(8))\n",
    "print(wins2.count(7))\n",
    "print(wins2.count(6))\n",
    "print(wins2.count(5))\n",
    "\n",
    "sum(wins2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wins1.count(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('AK_stationary_wins1.json', \"w\") as m:\n",
    "    m.write(json.dumps(wins1))\n",
    "with open('AK_stationary_wins2.json', \"w\") as m:\n",
    "    m.write(json.dumps(wins2))\n",
    "with open('AK_stationary_wins3.json', \"w\") as m:\n",
    "    m.write(json.dumps(wins3))\n",
    "with open('AK_stationary_wins4.json', \"w\") as m:\n",
    "    m.write(json.dumps(wins4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('AK_stationary_percents1.json', \"w\") as m:\n",
    "    m.write(json.dumps(percents1))\n",
    "with open('AK_stationary_percents2.json', \"w\") as m:\n",
    "    m.write(json.dumps(percents2))\n",
    "with open('AK_stationary_percents3.json', \"w\") as m:\n",
    "    m.write(json.dumps(percents3))\n",
    "with open('AK_stationary_percents4.json', \"w\") as m:\n",
    "    m.write(json.dumps(percents4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(wins1)\n",
    "len(wins2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wins1.count(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set-up chain for running on matchings! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/caranix/Desktop/Alaska_Git/data/large_matchings.json\", 'r') as rf:\n",
    "    matchings= json.load(rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ideal_population = sum(initial_partition[\"population\"].values()) / len(initial_partition)\n",
    "#print(ideal_population)\n",
    "\n",
    "proposal = partial(recom,\n",
    "                   pop_col=\"POPULATION\",\n",
    "                   pop_target=ideal_population,\n",
    "                   epsilon=0.05,\n",
    "                   node_repeats=2\n",
    "                  )\n",
    "\n",
    "\n",
    "compactness_bound = constraints.UpperBound(\n",
    "    lambda p: len(p[\"cut_edges\"]),\n",
    "    2*len(initial_partition[\"cut_edges\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip = GeographicPartition(G_loose, assignment=df[\"HDIST\"], updaters= my_updaters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "new_dg = nx.Graph()\n",
    "new_dg.add_edges_from(list({(ip.assignment[x[0]],ip.assignment[x[1]]) for x in ip[\"cut_edges\"]}) )\n",
    "print(len(new_dg.edges()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = MarkovChain(\n",
    "    proposal=proposal, \n",
    "    constraints=[\n",
    "        constraints.within_percent_of_ideal_population(initial_partition, .05),\n",
    "        compactness_bound, #single_flip_contiguous#no_more_discontiguous\n",
    "    ],\n",
    "    accept=accept.always_accept,\n",
    "    initial_state=ip,\n",
    "    total_steps=10000\n",
    ")\n",
    "\n",
    "\n",
    "#NOTE: The current Alaksa plan does not have population within 2%, I increased it to 5% population deviation.\n",
    "#NOTE: Alaska is not single flip contiguous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "A= parts_adjacency_matrix(ip)\n",
    "with open('AK_inital_state_largegraph.json', \"w\") as m:\n",
    "    m.write(json.dumps((A).tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for part in chain:\n",
    "#    1+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deinfe FKT algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx  # Requires at least netwrokx 2.3+\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "\n",
    "# Helper Functions\n",
    "def doNothing():\n",
    "    return 0;\n",
    "\n",
    "\n",
    "def find_faces(embd):\n",
    "    # Returns a list of faces of the planar embedding by\n",
    "    # the edges that bound the face\n",
    "    if embd is not None:\n",
    "        ed_list = list(embd.edges())\n",
    "        faces = []\n",
    "    if embd is not None:\n",
    "        for ed in embd.edges():\n",
    "        \n",
    "            if ed in ed_list:\n",
    "                faces.append(embd.traverse_face(ed[0], ed[1]))\n",
    "\n",
    "                for i in range(len(faces[-1])):\n",
    "                    ed_list.remove((faces[-1][i], faces[-1][(i + 1) % len(faces[-1])]))\n",
    "\n",
    "        face_edges = []\n",
    "        for face in faces:\n",
    "            face_edges.append([])\n",
    "            for i in range(len(face)):\n",
    "                face_edges[-1].append((face[i], face[(i + 1) % len(face)]))\n",
    "\n",
    "        return face_edges\n",
    "\n",
    "\n",
    "def toSkewSymmetricMatrix(A):\n",
    "    # Skew--symmetrize a matrix\n",
    "\n",
    "    A[(A == 1).T] = -1\n",
    "\n",
    "    return A\n",
    "\n",
    "\n",
    "def numberOfClockwiseEdges(face, edgesT1):\n",
    "    # Iterate over edges of a face to determine\n",
    "    # the number of positive orientations\n",
    "\n",
    "    clockwise = 0\n",
    "    for edge in face:\n",
    "        try:\n",
    "            edgesT1.index(edge)\n",
    "        except ValueError:\n",
    "            doNothing()\n",
    "        else:\n",
    "            clockwise += 1\n",
    "    return clockwise\n",
    "\n",
    "\n",
    "def isClockwise(e, face):\n",
    "    # Checks orientation of an edge on a face\n",
    "    try:\n",
    "        face.index(e);\n",
    "    except ValueError:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "\n",
    "# Main Function\n",
    "def FKT(A):\n",
    "    n = len(A)\n",
    "    B_graph = A[:]\n",
    "\n",
    "    G = nx.Graph(A)\n",
    "\n",
    "    tf, embd = nx.check_planarity(G)\n",
    "\n",
    "    faces = find_faces(embd)\n",
    "\n",
    "    T1 = nx.minimum_spanning_tree(G)\n",
    "    T1 = nx.Graph(T1)\n",
    "\n",
    "    mask = np.random.randint(2, size=(n, n))\n",
    "    mask = ((mask + mask.T) == 1)\n",
    "\n",
    "    B_digraph = A * mask\n",
    "\n",
    "    G = nx.DiGraph(B_digraph)\n",
    "\n",
    "    edgesT1 = T1.edges();\n",
    "    adj_T1 = (nx.adjacency_matrix(T1)).todense();\n",
    "\n",
    "    for edge in edgesT1:\n",
    "        if (B_digraph[edge[0], edge[1]] == 0):\n",
    "            adj_T1[edge[0], edge[1]] = 0\n",
    "        else:\n",
    "            adj_T1[edge[1], edge[0]] = 0\n",
    "\n",
    "    T1 = nx.DiGraph(adj_T1)\n",
    "    edgesT1 = list(T1.edges())\n",
    "    if embd is not None:\n",
    "        faces.sort(key=len)\n",
    "        faces.reverse()\n",
    "        faces.pop(0)\n",
    "        \n",
    "    if embd is not None:\n",
    "        while (len(faces) > 0):\n",
    "            index = -1;\n",
    "            for face in faces:\n",
    "                countMissingEdges = 0;\n",
    "                missingEdge = 0;\n",
    "                index += 1;\n",
    "                for edge in face:\n",
    "                    try:\n",
    "                        idx1 = edgesT1.index(edge);\n",
    "                    except ValueError:\n",
    "                        try:\n",
    "                            idx2 = edgesT1.index((edge[1], edge[0]));\n",
    "                        except ValueError:\n",
    "                            countMissingEdges += 1;\n",
    "                            missingEdge = edge;\n",
    "                        else:\n",
    "                            doNothing();\n",
    "                    else:\n",
    "                        doNothing();\n",
    "\n",
    "                if (countMissingEdges == 1):\n",
    "                # in this face, only one edge is missing.\n",
    "                # Place the missing edge such that the total number\n",
    "                # of clockwise edges of this face is odd\n",
    "                # add this edge to the spanning tree\n",
    "                    if ((numberOfClockwiseEdges(face, edgesT1)) % 2 == 1):\n",
    "                    # insert counterclockwise in adj_T1;\n",
    "                        if (isClockwise(missingEdge, face) == False):\n",
    "                            adj_T1[missingEdge[0], missingEdge[1]] = 1;\n",
    "                        else:\n",
    "                            adj_T1[missingEdge[1], missingEdge[0]] = 1;\n",
    "                    else:\n",
    "                    # insert clockwise in adj_T1\n",
    "                        if (isClockwise(missingEdge, face) == True):\n",
    "                            adj_T1[missingEdge[0], missingEdge[1]] = 1;\n",
    "                        else:\n",
    "                            adj_T1[missingEdge[1], missingEdge[0]] = 1;\n",
    "\n",
    "                # rebuild the graph\n",
    "                    T1 = nx.DiGraph(adj_T1);\n",
    "                    edgesT1 = list(T1.edges());\n",
    "\n",
    "                # remove the face that was found\n",
    "                    faceFound = faces.pop(index);\n",
    "                    break;\n",
    "        try: \n",
    "            return math.sqrt(np.linalg.det(toSkewSymmetricMatrix(adj_T1)));\n",
    "        except ValueError: \n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "percents1 = []\n",
    "wins1 = []\n",
    "percents2 = []\n",
    "wins2 = []\n",
    "percents3 = []\n",
    "wins3 = []\n",
    "percents4 = []\n",
    "wins4 = []\n",
    "num_edges = []\n",
    "num_matchings = []\n",
    "\n",
    "num_native_maj = []\n",
    "native_percents = []\n",
    "\n",
    "matrix = []\n",
    "edge_totals=[]\n",
    "\n",
    "num_edges_min= 1000000\n",
    "num_edges_max=0\n",
    "for c_part in chain:\n",
    "    \n",
    "    wins1.append(c_part[\"GOV18x\"].wins(\"Democratic\"))\n",
    "    percents1.append(sorted(c_part[\"GOV18x\"].percents(\"Democratic\")))\n",
    "    wins2.append(c_part[\"GOV18ns\"].wins(\"Democratic\"))\n",
    "    percents2.append(sorted(c_part[\"GOV18ns\"].percents(\"Democratic\")))\n",
    "    wins3.append(c_part[\"USH18x\"].wins(\"Democratic\"))\n",
    "    percents3.append(sorted(c_part[\"USH18x\"].percents(\"Democratic\")))\n",
    "    wins4.append(c_part[\"USH18ns\"].wins(\"Democratic\"))\n",
    "    percents4.append(sorted(c_part[\"USH18ns\"].percents(\"Democratic\")))\n",
    "    num_native_maj.append(c_part[\"Native_percent\"].wins(\"Native\"))\n",
    "    native_percents.append(sorted(c_part[\"Native_percent\"].percents(\"Native\")))\n",
    "    new_dg = nx.Graph()\n",
    "    new_dg.add_edges_from(list({(c_part.assignment[x[0]],c_part.assignment[x[1]]) for x in c_part[\"cut_edges\"]}) )\n",
    "    A = nx.adjacency_matrix(new_dg).todense()\n",
    "    if (A.sum()/2) < num_edges_min: \n",
    "        num_edges_min= (A.sum()/2)\n",
    "        mm= []\n",
    "        A= parts_adjacency_matrix(c_part) \n",
    "        mm.append(A.tolist())\n",
    "        with open('AK_min_small_180k.json', \"w\") as m:\n",
    "            m.write(json.dumps(mm))\n",
    "    if A.sum()/2 > num_edges_max: \n",
    "        num_edges_max= (A.sum()/2)\n",
    "        mm = []\n",
    "        A= parts_adjacency_matrix(c_part) \n",
    "        mm.append(A.tolist())\n",
    "        with open('AK_max_small_180k.json', \"w\") as m:\n",
    "            m.write(json.dumps(mm))\n",
    "    num_edges.append(A.sum()/2)\n",
    "    num_matchings.append(FKT(A))\n",
    "    \n",
    "\n",
    "allAssignments = {0: chain.state.assignment}\n",
    "for step in chain:\n",
    "        #allAssignments[chain.counter + 1] = [step.flips]\n",
    "        allAssignments[chain.counter] = step.assignment\n",
    "        edge_totals.append((numpy.matrix(parts_adjacency_matrix(step)).sum()/2))\n",
    "        matrix.append((parts_adjacency_matrix(step).tolist()))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(len(wins4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(wins1.count(10))\n",
    "print(wins1.count(9))\n",
    "print(wins1.count(8))\n",
    "print(wins1.count(7))\n",
    "print(wins1.count(6))\n",
    "print(wins1.count(5))\n",
    "print(wins1.count(5))\n",
    "\n",
    "sum(wins1)\n",
    "\n",
    "\n",
    "#print(len(matrix))\n",
    "print((percents1[50]))\n",
    "#print(len(num_matchings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('AK_180k_num_matchings.json', \"w\") as m:\n",
    "    m.write(json.dumps((num_matchings)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('AK_180k_num_edges.json', \"w\") as m:\n",
    "    m.write(json.dumps((num_edges)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_part\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "sns.distplot(wins2, kde=False)\n",
    "plt.axvline(x=ip[\"GOV18x\"].wins(\"Democratic\"),color='r',label='Enacted')\n",
    "plt.axvline(x=np.mean(wins2),color='g',label='Seat Average Mean')\n",
    "plt.ylabel(\"Number of Plans\")\n",
    "plt.xlabel(\"Number of Democrat House Seats\")\n",
    "plt.legend()\n",
    "#plt.savefig('GOV18xwins1.png')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "sns.distplot(wins1, kde=False)\n",
    "plt.axvline(x=ip[\"USH18ns\"].wins(\"Democratic\"),color='r',label='Enacted')\n",
    "plt.axvline(x=np.mean(wins4),color='g',label='Matchings Mean')\n",
    "plt.ylabel(\"Number of Plans\")\n",
    "plt.xlabel(\"Number of Democrat House Seats\")\n",
    "plt.legend()\n",
    "plt.savefig('USH18nswins4.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('AK_180k_num_matchings.json', \"w\") as m:\n",
    "    m.write(json.dumps((num_matchings)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('AK_180k_percents1.json', \"w\") as m:\n",
    "    m.write(json.dumps(percents1))\n",
    "with open('AK_180k_percents2.json', \"w\") as m:\n",
    "    m.write(json.dumps(percents2))\n",
    "with open('AK_180k_percents3.json', \"w\") as m:\n",
    "    m.write(json.dumps(percents3))\n",
    "with open('AK_180k_percents4.json', \"w\") as m:\n",
    "    m.write(json.dumps(percents4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('AK_180k_wins1.json', \"w\") as m:\n",
    "    m.write(json.dumps(wins1))\n",
    "with open('AK_180k_wins2.json', \"w\") as m:\n",
    "    m.write(json.dumps(wins2))\n",
    "with open('AK_180k_wins3.json', \"w\") as m:\n",
    "    m.write(json.dumps(wins3))\n",
    "with open('AK_180k_wins4.json', \"w\") as m:\n",
    "    m.write(json.dumps(wins4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('AK_180k_native_percents.json', \"w\") as m:\n",
    "    m.write(json.dumps(native_percents))\n",
    "    \n",
    "with open(\"AK_180k_num_native_maj.json\", 'w') as l: \n",
    "    l.write(json.dumps(num_native_maj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(\"30k_num_native_maj.json\", 'w') as l: \n",
    " #   l.write(json.dumps(num_native_maj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('AK_30k_num_edges.json', \"w\") as m:\n",
    " #   m.write(json.dumps(np.array(num_edges).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(num_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "sns.distplot(wins4,kde=False)\n",
    "plt.axvline(x=ip[\"USH18ns\"].native_percents(\"Democratic\"),color='r',label='Enacted')\n",
    "plt.axvline(x=np.mean(native_percents),color='g',label='Matchings Mean')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initial_partition = GeographicPartition(graph, assignment=\"HDIST\", updaters=my_updaters) #NOTE: assignment based on House Districts\n",
    "#sorted(initial_partition[\"Native_percent\"].percents(\"Native\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything below this is \"extra\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_dfs = {\"GOV18\": [],\n",
    "             \"USH18\": []}\n",
    "\n",
    "for key, val in chain_results.items():\n",
    "    chain_dfs[key] = pandas.DataFrame(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_results = {\"GOV18\": [],\n",
    "                 \"USH18\": []}\n",
    "\n",
    "for partition in chain:\n",
    "    for key, _ in chain_results.items():\n",
    "        chain_results[key].append(sorted(partition[key].percents(\"Democratic\"))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(edge_totals)\n",
    "print(max(edge_totals))\n",
    "print(min(edge_totals))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "    with open(\"./Assignments/AK_House_\"+str(i)+\".json\",'w') as wf:\n",
    "        json.dump(dict(allAssignments[i]), wf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = json.dumps(networkx.readwrite.json_graph.adjacency_data(graph))\n",
    "#It won't let me save graph due to a Polygon error- not a major issue for me atm \n",
    "#with open('/Users/caranix/Documents/alaska_graphAK_DATA.json') as f:\n",
    "#        data = json.load(f)\n",
    "#graph = networkx.readwrite.json_graph.adjacency_graph(data)\n",
    "#this is for when I can fix saving the grpah as a .json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#allAssignments[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dict(step.assignment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allAssignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = gpd.read_file(\"/Users/caranix/Documents/MGGG/AK_precincts/alaska_precincts.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "    df[\"plan\"+str(i)] = df.index.map(dict(allAssignments[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "df.plot(column=\"plan200\", cmap = \"hsv\")\n",
    "plt.axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "    if i % 100 == 0:\n",
    "        plt.figure()\n",
    "        df.plot(column=\"plan\"+str(i), cmap = \"hsv\")\n",
    "        plt.axis('off')\n",
    "        plt.savefig(\"./Pictures/AK_plot_\"+str(i)+\".png\", dpi=2000)  \n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_part = GeographicPartition(graph, assignment=df[\"plan11\"], updaters=my_updaters)#NOTE: assignment based on House Districts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_results = {\"GOV18\": [],\n",
    "                 \"USH18\": []}\n",
    "\n",
    "for key in chain_results.keys():\n",
    "    chain_results[key].append(sorted(new_part[key].percents(\"Democratic\"))) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_vals = [list(partition[\"population\"].values()) for partition in chain]\n",
    "data= pandas.DataFrame(pop_vals)\n",
    "print(data)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#house district 1 population values over 1,000 steps of chain \n",
    "print(data[0]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(data[0].idxmax())\n",
    "#print(data[0].max())\n",
    "\n",
    "for i in range(40):\n",
    "    print(\"on step \"+ str(data[i].idxmax()) + \" HD \" +str(i+1)+ \" reached it's max population: \" + str(data[i].max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.idxmax()\n",
    "#what step of chain the house district reaches a max. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a= data.max(axis=0) #max of each row \n",
    "#a.max(axis=0) \n",
    "print(a)\n",
    "a.idxmax()\n",
    "\n",
    "#max population of a plan \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.min(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.idxmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(40): \n",
    "    data[i].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_vals = [data[i].max() for i in range(40)]\n",
    "MAX= max(max_vals)\n",
    "#max_index= max_vals.maxidx()\n",
    "#print(\"max index\" +str(max_index))\n",
    "print(max_vals) #max value for each district \n",
    "print(\"highest population a district has: \" +str(MAX)) \n",
    "\n",
    "min_vals = [data[i].min() for i in range(40)]\n",
    "MIN= min(min_vals)\n",
    "print(min_vals)\n",
    "print(\"lowest population a district has: \" +str(MIN)) \n",
    "\n",
    "print(\"difference: \" + str(MAX-MIN))\n",
    "#note that this is not within the same plan, but over all of chain \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#within same plan..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deviation btwn single step in chain \n",
    "\n",
    "data.max(axis=1)- data.min(axis=1) #max of each row "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test= data.max(axis=1)- data.min(axis=1)\n",
    "print(test.idxmax()) #happens on the 426th step of chain \n",
    "print(test.max()) #the max divation is 1,754 people between two house districts. \n",
    "print(test.max()/ideal_population)\n",
    "\n",
    "print(test.idxmin()) #happens on the 0th step of chain \n",
    "print(test.min()) #the min deviation is 754 people between two house districts. \n",
    "print(test.min()/ideal_population)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "df.plot(column=\"plan426\", cmap = \"hsv\")\n",
    "plt.axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('edge_totals_small.json', \"w\") as m:\n",
    "    m.write(json.dumps(edge_totals))\n",
    "with open('matrix_small.json', \"w\") as l:\n",
    "    l.write(json.dumps(matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('edge_totals_small.json', \"w\") as m:\n",
    "    m.write(json.dumps(edge_totals))\n",
    "with open('matrix_small.json', \"w\") as l:\n",
    "    l.write(json.dumps(matrixs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seat_results= {\"GOV18\": [],\n",
    "               \"USH18\": []}\n",
    "#print(initial_partition)\n",
    "\n",
    "\n",
    "#for key, _ in seat_results.items():\n",
    " #   seat_results[key].append(initial_partition[key].seats())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS CHAIN IS  WORKING!! (but it isn't based on proposal, but propose_random_flip)\n",
    "\n",
    "\n",
    "#chain = gerrychain.MarkovChain(\n",
    "#    proposal=propose_random_flip,\n",
    "#    constraints=[constraints.within_percent_of_ideal_population(initial_partition, .03), no_more_discontiguous, compactness_bound],\n",
    "#    accept=always_accept,\n",
    "#    initial_state=initial_partition,\n",
    "#    total_steps=1000\n",
    "#)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
